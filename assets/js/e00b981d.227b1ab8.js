"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["3427"],{57667(e,n,i){i.r(n),i.d(n,{metadata:()=>t,default:()=>d,frontMatter:()=>a,contentTitle:()=>s,toc:()=>c,assets:()=>l});var t=JSON.parse('{"id":"hpc/ml_ai_hpc/intro","title":"Machine Learning (ML) and Artificial Intelligence (AI) on HPC","description":"Many people are interested in running ML and/or AI workflows on the HPC resources.  To help facilitate this we have created this section that will provide examples of how one might use our resources for ML and AI tasks.","source":"@site/docs/hpc/08_ml_ai_hpc/01_intro.md","sourceDirName":"hpc/08_ml_ai_hpc","slug":"/hpc/ml_ai_hpc/intro","permalink":"/docs/hpc/ml_ai_hpc/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/hpc/08_ml_ai_hpc/01_intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"Squash File System and Singularity","permalink":"/docs/hpc/containers/squash_file_system_and_singularity"},"next":{"title":"Single-GPU Training with PyTorch","permalink":"/docs/hpc/ml_ai_hpc/pytorch_intro"}}'),o=i(62615),r=i(30416);let a={},s="Machine Learning (ML) and Artificial Intelligence (AI) on HPC",l={},c=[];function h(e){let n={h1:"h1",header:"header",li:"li",ol:"ol",p:"p",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"machine-learning-ml-and-artificial-intelligence-ai-on-hpc",children:"Machine Learning (ML) and Artificial Intelligence (AI) on HPC"})}),"\n",(0,o.jsx)(n.p,{children:"Many people are interested in running ML and/or AI workflows on the HPC resources.  To help facilitate this we have created this section that will provide examples of how one might use our resources for ML and AI tasks."}),"\n",(0,o.jsx)(n.p,{children:"For ML we'll cover two prominent open-source deep learning frameworks, PyTorch and TensorFlow.  We'll show how to start with a single GPU example and then show more sophisticated examples."}),"\n",(0,o.jsx)(n.p,{children:"For AI we'll cover how to run a Hugging Face Large Language Model (LLM) and how to fine tune an LLM. Specifically, we provide guides on:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"LLM Inference: Use the standard Hugging Face transformers library for basic tasks, and also introduce vLLM, a high-throughput serving engine that offers faster inference and an OpenAI-compatible API."}),"\n",(0,o.jsx)(n.li,{children:"vLLM CLI: We provide examples of using the vllm command-line tool to quickly serve models and engage in interactive chat sessions."}),"\n",(0,o.jsx)(n.li,{children:"Fine-tuning LLMs: We provide a practical example of fine-tuning the Gemma model to follow specific instructions. This section compares the original model with our improved version, showing how to achieve better response quality on Torch."}),"\n"]})]})}function d(e={}){let{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},30416(e,n,i){i.d(n,{R:()=>a,x:()=>s});var t=i(59471);let o={},r=t.createContext(o);function a(e){let n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);