"use strict";(self.webpackChunkrts_docs_dev=self.webpackChunkrts_docs_dev||[]).push([["9818"],{14589:function(e,n,t){t.r(n),t.d(n,{frontMatter:()=>s,default:()=>p,contentTitle:()=>a,assets:()=>d,toc:()=>l,metadata:()=>i});var i=JSON.parse('{"id":"genai/how_to_guides/embeddings","title":"Embeddings","description":"While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs \\"generate\\" tokens (\\"text\\") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate \\"embeddings\\" as their output. Here, we shall walk through a task of generating embeddings from a text document.","source":"@site/docs/genai/04_how_to_guides/02_embeddings.mdx","sourceDirName":"genai/04_how_to_guides","slug":"/genai/how_to_guides/embeddings","permalink":"/rts-docs-dev/pr-preview/pr-117/docs/genai/how_to_guides/embeddings","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-ITS/rts-docs-dev/blob/main/docs/genai/04_how_to_guides/02_embeddings.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"genaiSidebar","previous":{"title":"Effect of Temperature","permalink":"/rts-docs-dev/pr-preview/pr-117/docs/genai/how_to_guides/temperature"},"next":{"title":"Retrieval-augmented generation","permalink":"/rts-docs-dev/pr-preview/pr-117/docs/genai/how_to_guides/retrieval_augmented_generation"}}'),o=t(74132),r=t(25998);let s={},a="Embeddings",d={},l=[{value:"How to generate embeddings from plain text:",id:"how-to-generate-embeddings-from-plain-text",level:2},{value:"Applications of embeddings",id:"applications-of-embeddings",level:2}];function c(e){let n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"embeddings",children:"Embeddings"})}),"\n",(0,o.jsx)(n.p,{children:'While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs "generate" tokens ("text") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate "embeddings" as their output. Here, we shall walk through a task of generating embeddings from a text document.'}),"\n",(0,o.jsx)(n.mermaid,{value:'flowchart LR;\n    A["Input natual language text string <br> GenAI can be used for research"]\n    B["Encoder-only LLM"]\n    C["Vector embedding <br> [0.052587852, 0.094195396, 0.24439038, 0.104940414, ...]"]\n    A-- "Input" --\x3eB;\n    B-- "Output" --\x3eC;'}),"\n",(0,o.jsx)(n.h2,{id:"how-to-generate-embeddings-from-plain-text",children:"How to generate embeddings from plain text:"}),"\n",(0,o.jsxs)(n.p,{children:["The snippet below uses the ",(0,o.jsx)(n.code,{children:"text-embedding-3-small"})," model to create 32-dimensional floating point vector embeddings for the input string:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from portkey_ai import Portkey\n\nportkey = Portkey(\n    base_url="https://ai-gateway.apps.cloud.rt.nyu.edu/v1/",\n    api_key="",  # Replace with your Portkey API key\n    virtual_key="",  # Replace with your virtual key\n)\n\nresponse = portkey.embeddings.create(\n    model="text-embedding-3-small",\n    input="GenAI can be used for research.",\n    encoding_format="float",\n    dimensions=32,\n)\n\nprint(response["data"][0].embedding)\n'})}),"\n",(0,o.jsx)(n.p,{children:"and gives the following response:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"[0.052587852, 0.094195396, 0.24439038, 0.104940414, -0.028921358, -0.31591928, -0.1846261, 0.221018, 0.033215445, -0.1382735, -0.14776362, -0.15058714, 0.057725072, -0.23435123, 0.07956805, -0.32156628, -0.08454841, 0.04066637, -0.022215525, 0.19090058, -0.11160703, 0.22258662, -0.06843088, -0.22854735, 0.1033718, -0.38085997, 0.2933312, -0.023215517, 0.20768477, -0.039333045, 0.17192031, -0.14180289]\n"})}),"\n",(0,o.jsx)(n.h2,{id:"applications-of-embeddings",children:"Applications of embeddings"}),"\n",(0,o.jsx)(n.p,{children:"Embeddings have the ability to encode the semantic meaning of the text. Thus, they find applications in:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"retrieval-augmented generation"}),"\n",(0,o.jsx)(n.li,{children:"search"}),"\n",(0,o.jsx)(n.li,{children:"classification\namong others"}),"\n"]})]})}function p(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},25998:function(e,n,t){t.d(n,{Z:()=>a,a:()=>s});var i=t(39546);let o={},r=i.createContext(o);function s(e){let n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);