"use strict";(self.webpackChunkrts_docs_dev=self.webpackChunkrts_docs_dev||[]).push([["1285"],{51821:function(e,n,i){i.r(n),i.d(n,{frontMatter:()=>a,default:()=>h,contentTitle:()=>d,assets:()=>o,toc:()=>l,metadata:()=>t});var t=JSON.parse('{"id":"hpc/ml_ai_hpc/llm_fine_tuning","title":"Fine tune LLMs on HPC","description":"Model and Dataset Selection Rationale","source":"@site/docs/hpc/08_ml_ai_hpc/04_llm_fine_tuning.md","sourceDirName":"hpc/08_ml_ai_hpc","slug":"/hpc/ml_ai_hpc/llm_fine_tuning","permalink":"/rts-docs-dev/pr-preview/pr-94/docs/hpc/ml_ai_hpc/llm_fine_tuning","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-ITS/rts-docs-dev/blob/main/docs/hpc/08_ml_ai_hpc/04_llm_fine_tuning.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"LLMs on HPC","permalink":"/rts-docs-dev/pr-preview/pr-94/docs/hpc/ml_ai_hpc/llm_on_hpc"},"next":{"title":"Open OnDemand (OOD) with Conda/Singularity","permalink":"/rts-docs-dev/pr-preview/pr-94/docs/hpc/ood/open_on_demand"}}'),r=i(74132),s=i(25998);let a={},d="Fine tune LLMs on HPC",o={},l=[{value:"Model and Dataset Selection Rationale",id:"model-and-dataset-selection-rationale",level:2},{value:"Dataset Overview",id:"dataset-overview",level:3},{value:"Fine-tuning Benefits",id:"fine-tuning-benefits",level:3},{value:"Before and After Fine-tuning Comparison",id:"before-and-after-fine-tuning-comparison",level:2},{value:"Example Prompt: &quot;Explain quantum computing in simple terms for a beginner&quot;",id:"example-prompt-explain-quantum-computing-in-simple-terms-for-a-beginner",level:3},{value:"Before Fine-tuning (Base LLaMA2-7B):",id:"before-fine-tuning-base-llama2-7b",level:4},{value:"After Fine-tuning (LLaMA2-7B + LoRA on Guanaco):",id:"after-fine-tuning-llama2-7b--lora-on-guanaco",level:4},{value:"System Environment Setup",id:"system-environment-setup",level:2},{value:"Singularity Container &amp; Overlay Configuration",id:"singularity-container--overlay-configuration",level:3},{value:"Python Environment and Dependency Installation",id:"python-environment-and-dependency-installation",level:3},{value:"Model Cache Configuration for Hugging Face",id:"model-cache-configuration-for-hugging-face",level:3},{value:"Operational Troubleshooting: Common Errors and Recommended Fixes",id:"operational-troubleshooting-common-errors-and-recommended-fixes",level:2},{value:"1. Filesystem and Path Setup Issues",id:"1-filesystem-and-path-setup-issues",level:3},{value:"2. Container Runtime and Overlay Mounting Errors",id:"2-container-runtime-and-overlay-mounting-errors",level:3},{value:"3. Python Package Installation and Environment Setup Errors",id:"3-python-package-installation-and-environment-setup-errors",level:3},{value:"4. Disk Quota and Cache Management Issues",id:"4-disk-quota-and-cache-management-issues",level:3},{value:"5. Slurm Job Submission and Runtime Failures",id:"5-slurm-job-submission-and-runtime-failures",level:3},{value:"Recommended Best Practices for Stable Execution",id:"recommended-best-practices-for-stable-execution",level:2},{value:"LoRA Configuration Parameters",id:"lora-configuration-parameters",level:2},{value:"sbatch Job Script for Model Training",id:"sbatch-job-script-for-model-training",level:2},{value:"<strong>Training Script: <code>train_phi4.py</code></strong>",id:"training-script-train_phi4py",level:3},{value:"Generated Output Artifacts",id:"generated-output-artifacts",level:2},{value:"Training Completion Summary",id:"training-completion-summary",level:2}];function c(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"fine-tune-llms-on-hpc",children:"Fine tune LLMs on HPC"})}),"\n",(0,r.jsx)(n.h2,{id:"model-and-dataset-selection-rationale",children:"Model and Dataset Selection Rationale"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Component"}),(0,r.jsx)(n.th,{children:"Configuration"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Model"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"NousResearch/Llama-2-7b-chat-hf"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Dataset"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"timdettmers/openassistant-guanaco"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Justification"}),(0,r.jsx)(n.td,{children:"High-quality instruction-following dataset with conversational exchanges designed to improve model's ability to follow complex instructions, maintain context, and provide structured responses"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"dataset-overview",children:"Dataset Overview"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"timdettmers/openassistant-guanaco"})," dataset is a high-quality instruction-following dataset containing conversational exchanges between humans and AI assistants. It includes diverse question-answer pairs covering topics like creative writing, problem-solving, factual queries, and technical explanations. The dataset is specifically designed to train models to follow instructions and provide helpful, harmless, and honest responses."]}),"\n",(0,r.jsx)(n.h3,{id:"fine-tuning-benefits",children:"Fine-tuning Benefits"}),"\n",(0,r.jsx)(n.p,{children:"Fine-tuning LLaMA2 on this dataset significantly improves the model's ability to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Follow complex instructions"}),": Better understanding of multi-step requests and nuanced prompts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Maintain conversational context"}),": Improved coherence in longer dialogues"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Provide structured responses"}),": Enhanced ability to format answers appropriately"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reduce harmful outputs"}),": Training on carefully curated data reduces problematic responses"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"before-and-after-fine-tuning-comparison",children:"Before and After Fine-tuning Comparison"}),"\n",(0,r.jsx)(n.h3,{id:"example-prompt-explain-quantum-computing-in-simple-terms-for-a-beginner",children:'Example Prompt: "Explain quantum computing in simple terms for a beginner"'}),"\n",(0,r.jsx)(n.h4,{id:"before-fine-tuning-base-llama2-7b",children:"Before Fine-tuning (Base LLaMA2-7B):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Quantum computing uses quantum bits or qubits instead of classical bits. Qubits can be in superposition states and can be entangled. This allows quantum computers to perform certain calculations exponentially faster than classical computers for specific problems like factoring large numbers and simulating quantum systems.\n"})}),"\n",(0,r.jsx)(n.h4,{id:"after-fine-tuning-llama2-7b--lora-on-guanaco",children:"After Fine-tuning (LLaMA2-7B + LoRA on Guanaco):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'Great question! Let me break down quantum computing in simple terms:\n\n**Think of it like this**: Regular computers use bits that are either 0 or 1 (like light switches that are either ON or OFF). Quantum computers use "quantum bits" or "qubits" that can be 0, 1, or both at the same time - imagine a coin that\'s spinning in the air, being both heads and tails until it lands.\n\n**Why this matters**: This allows quantum computers to:\n- Try many solutions to a problem simultaneously\n- Solve certain types of problems much faster than regular computers\n- Handle complex calculations that would take classical computers thousands of years\n\n**Real applications**: Password breaking, drug discovery, weather prediction, and financial modeling.\n\nThe fine-tuned model provides clearer explanations with better structure, analogies, and practical context!\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"system-environment-setup",children:"System Environment Setup"}),"\n",(0,r.jsx)(n.h3,{id:"singularity-container--overlay-configuration",children:"Singularity Container & Overlay Configuration"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Component"}),(0,r.jsx)(n.th,{children:"Configuration"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Singularity Image"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/scratch/work/public/singularity/cuda11.2.2-cudnn8-devel-ubuntu20.04.sif"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Overlay"}),(0,r.jsxs)(n.td,{children:["Created using ",(0,r.jsx)(n.code,{children:"singularity overlay create --size 25000 overlay-25GB-conda.ext3"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Conda Path"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"/ext3/miniconda3"})," within overlay"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Singularity Shell Command"}),(0,r.jsx)(n.td,{children:"See below"})]})]})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"singularity shell --nv \\\n  --overlay /scratch/<NetID>/fine-tune/overlay-25GB-conda.ext3:rw \\\n  /scratch/work/public/singularity/cuda11.2.2-cudnn8-devel-ubuntu20.04.sif\n"})}),"\n",(0,r.jsx)(n.h3,{id:"python-environment-and-dependency-installation",children:"Python Environment and Dependency Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"bash Miniconda3-latest-Linux-x86_64.sh -b -p /ext3/miniconda3\nsource /ext3/miniconda3/bin/activate\npip install torch transformers datasets accelerate peft trl\n"})}),"\n",(0,r.jsx)(n.h3,{id:"model-cache-configuration-for-hugging-face",children:"Model Cache Configuration for Hugging Face"}),"\n",(0,r.jsx)(n.p,{children:"To avoid exceeding home directory quotas during large model downloads:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"export HF_HOME=/scratch/<NetID>/.cache/huggingface\n"})}),"\n",(0,r.jsx)(n.p,{children:"Ensure this is set both interactively and within sbatch scripts."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"operational-troubleshooting-common-errors-and-recommended-fixes",children:"Operational Troubleshooting: Common Errors and Recommended Fixes"}),"\n",(0,r.jsxs)(n.p,{children:["This section provides a comprehensive overview of all environment-related issues encountered during the fine-tuning of ",(0,r.jsx)(n.code,{children:"NousResearch/Llama-2-7b-chat-hf"})," on the NYU Greene HPC cluster. Each entry includes the error symptom, root cause, and resolution strategy, categorized for clarity."]}),"\n",(0,r.jsx)(n.h3,{id:"1-filesystem-and-path-setup-issues",children:"1. Filesystem and Path Setup Issues"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Problem"}),(0,r.jsx)(n.th,{children:"Symptom"}),(0,r.jsx)(n.th,{children:"Cause"}),(0,r.jsx)(n.th,{children:"Resolution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Incorrect overlay filename"}),(0,r.jsxs)(n.td,{children:["No such file: ",(0,r.jsx)(n.code,{children:"overlay-50GB-500K.ext3.gz"})]}),(0,r.jsx)(n.td,{children:"The filename was incorrectly assumed"}),(0,r.jsxs)(n.td,{children:["Use ",(0,r.jsx)(n.code,{children:"ls /scratch/work/public/overlay-fs-ext3/"})," to verify the correct file: ",(0,r.jsx)(n.code,{children:"overlay-50G-10M.ext3.gz"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Compressed overlay used directly"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"FATAL: while loading overlay images..."})}),(0,r.jsxs)(n.td,{children:["Attempted to use ",(0,r.jsx)(n.code,{children:".gz"})," file directly with Singularity"]}),(0,r.jsxs)(n.td,{children:["Run ",(0,r.jsx)(n.code,{children:"gunzip overlay-50G-10M.ext3.gz"})," before using the file"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Overlay missing in working directory"}),(0,r.jsx)(n.td,{children:"sbatch cannot find the overlay file"}),(0,r.jsx)(n.td,{children:"Overlay not copied to the training directory"}),(0,r.jsxs)(n.td,{children:["Ensure the overlay file is placed in ",(0,r.jsx)(n.code,{children:"/scratch/<NetID>/fine-tune/"})," where sbatch accesses it"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Invalid overlay structure"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"FATAL: could not create upper dir"})}),(0,r.jsxs)(n.td,{children:["Overlay created via ",(0,r.jsx)(n.code,{children:"fallocate"})," + ",(0,r.jsx)(n.code,{children:"mkfs.ext3"}),", missing necessary internal structure"]}),(0,r.jsxs)(n.td,{children:["Always use ",(0,r.jsx)(n.code,{children:"singularity overlay create --size 25000"})," to create overlays"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"2-container-runtime-and-overlay-mounting-errors",children:"2. Container Runtime and Overlay Mounting Errors"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Problem"}),(0,r.jsx)(n.th,{children:"Symptom"}),(0,r.jsx)(n.th,{children:"Cause"}),(0,r.jsx)(n.th,{children:"Resolution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"GPU warning on login node"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"WARNING: Could not find any nv files"})}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"--nv"})," flag used outside GPU-enabled session"]}),(0,r.jsxs)(n.td,{children:["Ignore the warning, or only use ",(0,r.jsx)(n.code,{children:"--nv"})," within a ",(0,r.jsx)(n.code,{children:"srun --gres=gpu:1"})," session"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Overlay locked by another process"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"overlay in use by another process"})}),(0,r.jsx)(n.td,{children:"An interactive container shell using the overlay was still active"}),(0,r.jsxs)(n.td,{children:["Run ",(0,r.jsx)(n.code,{children:"lsof"})," or ",(0,r.jsx)(n.code,{children:"ps aux"})," and terminate blocking process"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"3-python-package-installation-and-environment-setup-errors",children:"3. Python Package Installation and Environment Setup Errors"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Problem"}),(0,r.jsx)(n.th,{children:"Symptom"}),(0,r.jsx)(n.th,{children:"Cause"}),(0,r.jsx)(n.th,{children:"Resolution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"which pip"})," returns ",(0,r.jsx)(n.code,{children:"Illegal option --"})]}),(0,r.jsx)(n.td,{children:"Unexpected error when checking pip"}),(0,r.jsxs)(n.td,{children:["Uses ",(0,r.jsx)(n.code,{children:"/usr/bin/which"})," instead of Bash built-in"]}),(0,r.jsxs)(n.td,{children:["Use ",(0,r.jsx)(n.code,{children:"command -v pip"})," or simply run ",(0,r.jsx)(n.code,{children:"pip --version"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"xformers"})," install fails due to missing torch"]}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"No module named torch"})," during install"]}),(0,r.jsxs)(n.td,{children:["PyTorch not installed before building ",(0,r.jsx)(n.code,{children:"xformers"})]}),(0,r.jsxs)(n.td,{children:["Install torch first: ",(0,r.jsx)(n.code,{children:"pip install torch"}),", then ",(0,r.jsx)(n.code,{children:"pip install xformers"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Missing ",(0,r.jsx)(n.code,{children:"transformers"})," in sbatch"]}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"ImportError: No module named transformers"})}),(0,r.jsx)(n.td,{children:"Conda not activated in job script"}),(0,r.jsxs)(n.td,{children:["Add ",(0,r.jsx)(n.code,{children:"source /ext3/miniconda3/bin/activate"})," before executing the training script"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Installed pip packages not found"}),(0,r.jsx)(n.td,{children:"Training job fails to locate modules"}),(0,r.jsx)(n.td,{children:"pip used outside overlay context"}),(0,r.jsxs)(n.td,{children:["Only install packages while the overlay is mounted with ",(0,r.jsx)(n.code,{children:":rw"})," in an active container session"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"4-disk-quota-and-cache-management-issues",children:"4. Disk Quota and Cache Management Issues"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Problem"}),(0,r.jsx)(n.th,{children:"Symptom"}),(0,r.jsx)(n.th,{children:"Cause"}),(0,r.jsx)(n.th,{children:"Resolution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Quota exceeded on home"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"OSError: [Errno 122] Disk quota exceeded: ~/.cache/huggingface"})}),(0,r.jsxs)(n.td,{children:["Default HuggingFace cache path inside ",(0,r.jsx)(n.code,{children:"/home"})]}),(0,r.jsxs)(n.td,{children:["Set ",(0,r.jsx)(n.code,{children:"HF_HOME=/scratch/$USER/.cache/huggingface"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Cache redownloading on each sbatch"}),(0,r.jsx)(n.td,{children:"Hugging Face cache not shared"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"HF_HOME"})," not consistently defined"]}),(0,r.jsxs)(n.td,{children:["Persist and reuse the same ",(0,r.jsx)(n.code,{children:"HF_HOME"})," path across runs"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"5-slurm-job-submission-and-runtime-failures",children:"5. Slurm Job Submission and Runtime Failures"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Problem"}),(0,r.jsx)(n.th,{children:"Symptom"}),(0,r.jsx)(n.th,{children:"Cause"}),(0,r.jsx)(n.th,{children:"Resolution"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Invalid Slurm account"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"sbatch: Invalid account"})}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"--account"})," flag not set or invalid"]}),(0,r.jsxs)(n.td,{children:["Use ",(0,r.jsx)(n.code,{children:"--account=pr_100_tandon_priority"})]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Conda environment not recognized"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"No module named transformers"})}),(0,r.jsx)(n.td,{children:"Activation missing in sbatch"}),(0,r.jsxs)(n.td,{children:["Add ",(0,r.jsx)(n.code,{children:"source /ext3/miniconda3/bin/activate"})," in sbatch"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Overlay not found during job"}),(0,r.jsx)(n.td,{children:"sbatch fails to locate file"}),(0,r.jsx)(n.td,{children:"Overlay not placed in expected directory"}),(0,r.jsxs)(n.td,{children:["Ensure all relevant files are in ",(0,r.jsx)(n.code,{children:"/scratch/<NetID>/fine-tune/"})," or update paths accordingly"]})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"recommended-best-practices-for-stable-execution",children:"Recommended Best Practices for Stable Execution"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Recommendation"}),(0,r.jsx)(n.th,{children:"Rationale"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Use ",(0,r.jsx)(n.code,{children:"singularity overlay create"})," for overlay creation"]}),(0,r.jsxs)(n.td,{children:["Ensures ",(0,r.jsx)(n.code,{children:"upper/"})," and ",(0,r.jsx)(n.code,{children:"work/"})," directories are properly set up"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Install pip packages only after mounting overlay"}),(0,r.jsx)(n.td,{children:"Ensures packages persist and are isolated inside the overlay"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Activate Conda explicitly in sbatch"}),(0,r.jsx)(n.td,{children:"Slurm jobs do not inherit interactive shell environments"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Set ",(0,r.jsx)(n.code,{children:"HF_HOME"})," to ",(0,r.jsx)(n.code,{children:"/scratch"})]}),(0,r.jsx)(n.td,{children:"Prevents hitting disk quota limits in home directories"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Avoid ",(0,r.jsx)(n.code,{children:'return_tensors="pt"'})," in tokenizer mapping"]}),(0,r.jsx)(n.td,{children:"Leads to shape mismatch errors in batched training"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:["Use subset sampling (e.g., ",(0,r.jsx)(n.code,{children:"train[:1%]"}),") for testing"]}),(0,r.jsx)(n.td,{children:"Minimizes resource consumption and enables fast debugging"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"lora-configuration-parameters",children:"LoRA Configuration Parameters"}),"\n",(0,r.jsx)(n.p,{children:"LoRA (Low-Rank Adaptation) is a technique for efficiently fine-tuning large models with reduced computational cost. It adapts the model's layers by adding low-rank matrices while maintaining the original model's parameters. This enables efficient training with fewer resources."}),"\n",(0,r.jsxs)(n.p,{children:["Learn more about LoRA ",(0,r.jsx)(n.a,{href:"https://huggingface.co/learn/llm-course/en/chapter11/4",children:"here"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"Here are the configuration parameters used for LoRA in this fine-tuning setup:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'peft_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],\n    lora_dropout=0.05,\n    bias="none",\n    task_type=TaskType.CAUSAL_LM\n)\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"sbatch-job-script-for-model-training",children:"sbatch Job Script for Model Training"}),"\n",(0,r.jsx)(n.h3,{id:"training-script-train_phi4py",children:(0,r.jsxs)(n.strong,{children:["Training Script: ",(0,r.jsx)(n.code,{children:"train_phi4.py"})]})}),"\n",(0,r.jsxs)(n.p,{children:["The script ",(0,r.jsx)(n.code,{children:"train_phi4.py"})," is used for training the model. Below is the full content of the script:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nFine-tune LLaMA2-7B using LoRA on OpenAssistant Guanaco dataset\nOptimized for NYU Greene HPC environment\n"""\n\nimport os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom trl import SFTTrainer\n\ndef main():\n    # Model and dataset configuration\n    model_name = "NousResearch/Llama-2-7b-chat-hf"\n    dataset_name = "timdettmers/openassistant-guanaco"\n    output_dir = "./llama2_output"\n    \n    # Load tokenizer and model\n    print("Loading tokenizer and model...")\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    tokenizer.pad_token = tokenizer.eos_token\n    \n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        torch_dtype=torch.float16,\n        device_map="auto",\n        trust_remote_code=True\n    )\n    \n    # LoRA configuration\n    peft_config = LoraConfig(\n        r=8,\n        lora_alpha=16,\n        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],\n        lora_dropout=0.05,\n        bias="none",\n        task_type=TaskType.CAUSAL_LM\n    )\n    \n    # Apply LoRA to model\n    model = get_peft_model(model, peft_config)\n    model.print_trainable_parameters()\n    \n    # Load and prepare dataset\n    print("Loading dataset...")\n    dataset = load_dataset(dataset_name, split="train[:1%]")  # Use 1% for testing\n    \n    def format_instruction(sample):\n        return f"### Human: {sample[\'text\']}\\n### Assistant: "\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        per_device_train_batch_size=4,\n        gradient_accumulation_steps=4,\n        num_train_epochs=1,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=10,\n        save_steps=50,\n        save_total_limit=2,\n        remove_unused_columns=False,\n        dataloader_pin_memory=False,\n    )\n    \n    # Initialize trainer\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=dataset,\n        dataset_text_field="text",\n        max_seq_length=512,\n        tokenizer=tokenizer,\n        args=training_args,\n        peft_config=peft_config,\n    )\n    \n    # Start training\n    print("Starting training...")\n    trainer.train()\n    \n    # Save the model\n    print("Saving model...")\n    trainer.save_model()\n    tokenizer.save_pretrained(output_dir)\n    \n    print("Training completed successfully!")\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,r.jsx)(n.p,{children:"You can now run the script in your Singularity container environment to train your LLaMA2 model with LoRA fine-tuning."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n#SBATCH --job-name=llama2-finetune\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=4\n#SBATCH --mem=40GB\n#SBATCH --gres=gpu:1\n#SBATCH --time=12:00:00\n#SBATCH --output=/scratch/<NetID>/fine-tune/phi4_train_%j.out\n#SBATCH --error=/scratch/<NetID>/fine-tune/phi4_train_%j.err\n#SBATCH --mail-type=END,FAIL\n#SBATCH --mail-user=<NetID>@nyu.edu\n\nexport HF_HOME=/scratch/<NetID>/.cache/huggingface\n\nsingularity exec --nv \\\n  --overlay /scratch/<NetID>/fine-tune/overlay-25GB-conda.ext3:rw \\\n  /scratch/work/public/singularity/cuda11.2.2-cudnn8-devel-ubuntu20.04.sif \\\n  /bin/bash -c "\n    source /ext3/miniconda3/bin/activate\n    cd /scratch/<NetID>/fine-tune\n    python train_phi4.py\n"\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"generated-output-artifacts",children:"Generated Output Artifacts"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"File"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"adapter_model.safetensors"})}),(0,r.jsx)(n.td,{children:"LoRA adapter weights"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"adapter_config.json"})}),(0,r.jsx)(n.td,{children:"Adapter architecture definition"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"trainer_state.json"})}),(0,r.jsx)(n.td,{children:"Training metadata"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"training_args.bin"})}),(0,r.jsx)(n.td,{children:"Saved training configuration"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"tokenizer_config.json"}),", ",(0,r.jsx)(n.code,{children:"tokenizer.json"})]}),(0,r.jsx)(n.td,{children:"Tokenizer data"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["Location: ",(0,r.jsx)(n.code,{children:"/scratch/<NetID>/fine-tune/llama2_output/checkpoint-13/"})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"training-completion-summary",children:"Training Completion Summary"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Epochs"}),(0,r.jsx)(n.th,{children:"Steps"}),(0,r.jsx)(n.th,{children:"Status"})]})}),(0,r.jsx)(n.tbody,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"13"}),(0,r.jsx)(n.td,{children:"Completed successfully"})]})})]})]})}function h(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},25998:function(e,n,i){i.d(n,{Z:()=>d,a:()=>a});var t=i(39546);let r={},s=t.createContext(r);function a(e){let n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);