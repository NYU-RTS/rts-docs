"use strict";(self.webpackChunkrts_docs_dev=self.webpackChunkrts_docs_dev||[]).push([["9818"],{8579:function(e,n,t){t.r(n),t.d(n,{frontMatter:()=>s,default:()=>p,toc:()=>l,metadata:()=>i,assets:()=>d,contentTitle:()=>o});var i=JSON.parse('{"id":"genai/how_to_guides/embeddings","title":"Generating embeddings","description":"While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs \\"generate\\" tokens (\\"text\\") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate \\"embeddings\\" as their output. Here, we shall walk through a task of generating embeddings from a text snippet.","source":"@site/docs/genai/04_how_to_guides/02_embeddings.mdx","sourceDirName":"genai/04_how_to_guides","slug":"/genai/how_to_guides/embeddings","permalink":"/rts-docs/pr-preview/pr-143/docs/genai/how_to_guides/embeddings","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-ITS/rts-docs-dev/blob/main/docs/genai/04_how_to_guides/02_embeddings.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"genaiSidebar","previous":{"title":"Effect of Temperature","permalink":"/rts-docs/pr-preview/pr-143/docs/genai/how_to_guides/temperature"},"next":{"title":"Retrieval-augmented generation","permalink":"/rts-docs/pr-preview/pr-143/docs/genai/how_to_guides/retrieval_augmented_generation"}}'),r=t(74132),a=t(89447);let s={},o="Generating embeddings",d={},l=[{value:"Applications of embeddings",id:"applications-of-embeddings",level:2}];function c(e){let n={admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,a.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"generating-embeddings",children:"Generating embeddings"})}),"\n",(0,r.jsx)(n.p,{children:'While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs "generate" tokens ("text") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate "embeddings" as their output. Here, we shall walk through a task of generating embeddings from a text snippet.'}),"\n",(0,r.jsx)(n.mermaid,{value:'flowchart LR;\n    A["natual language text: <br> *GenAI can be used for research*"]\n    B["encoder-only LLM"]\n    C["vector embedding <br> [0.052, 0.094, 0.244, ...]"]\n    A-- "Input" --\x3eB;\n    B-- "Output" --\x3eC;'}),"\n",(0,r.jsx)(n.admonition,{type:"tip",children:(0,r.jsx)(n.p,{children:"Embeddings have the ability to encode the semantic meaning of the natual language text/images!"})}),"\n",(0,r.jsxs)(n.p,{children:["The snippet below uses the ",(0,r.jsx)(n.code,{children:"text-embedding-3-small"})," model to create 32-dimensional floating point vector embeddings for the input string:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from portkey_ai import Portkey\n\nportkey = Portkey(\n    base_url="https://ai-gateway.apps.cloud.rt.nyu.edu/v1/",\n    api_key="",  # Replace with your Portkey API key\n    virtual_key="",  # Replace with your virtual key\n)\n\nresponse = portkey.embeddings.create(\n    model="text-embedding-3-small",\n    input="GenAI can be used for research.",\n    encoding_format="float",\n    dimensions=32,\n)\n\nprint(response["data"][0].embedding)\n'})}),"\n",(0,r.jsx)(n.p,{children:"and gives the following response:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[0.052587852, 0.094195396, 0.24439038, 0.104940414, -0.028921358, -0.31591928, -0.1846261, 0.221018, 0.033215445, -0.1382735, -0.14776362, -0.15058714, 0.057725072, -0.23435123, 0.07956805, -0.32156628, -0.08454841, 0.04066637, -0.022215525, 0.19090058, -0.11160703, 0.22258662, -0.06843088, -0.22854735, 0.1033718, -0.38085997, 0.2933312, -0.023215517, 0.20768477, -0.039333045, 0.17192031, -0.14180289]\n"})}),"\n",(0,r.jsx)(n.h2,{id:"applications-of-embeddings",children:"Applications of embeddings"}),"\n",(0,r.jsx)(n.p,{children:"Embeddings are typically used for:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"retrieval-augmented generation"}),"\n",(0,r.jsx)(n.li,{children:"search"}),"\n",(0,r.jsx)(n.li,{children:"classification"}),"\n"]}),"\n",(0,r.jsx)(n.admonition,{type:"info",children:(0,r.jsxs)(n.p,{children:["Embeddings are typically stored in a ",(0,r.jsx)(n.em,{children:"vector"})," database which is designed for efficient storage and fast retrieval of vectors."]})})]})}function p(e={}){let{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},89447:function(e,n,t){t.d(n,{Z:()=>o,a:()=>s});var i=t(39546);let r={},a=i.createContext(r);function s(e){let n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);