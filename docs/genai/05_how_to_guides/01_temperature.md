# Temperature

Generating text (or images) from LLMs is inherently probabilistic. However, as an end user you have many parameters at your disposal to tweak the behavior of LLMs. Of these, temperature is the most commonly used. Broadly, it controls the randonmess of the generated text. A lower temperature produces more deterministic outputs, while a higher temperature produces more random "creative" output.

:::tip

Reasoning models do not support the temperature parameter. Instead, refer to the thinking budget parameter for reasoning models.

:::
