# Quickstart

:::danger[Access to Portkey is only permitted via NYU VPN]
The machine sending requests to the LLM gateway needs to be connected to the NYU VPN to access the LLM gateway. If it is not connected to the VPN, your requests will timeout and result in connection errors.

If you are sending requests from a server like Colab notebook while your laptop is on the VPN the requests will fail as the machine sending the requests is the Colab server, not your laptop!
:::


## Getting started with the LLM gateway

:::tip[Gateway URL]
Whenever you instantiate a Portkey client, the `base_url` must be set to `base_url="https://ai-gateway.apps.cloud.rt.nyu.edu/v1/"`. If you miss this parameter you would be connecting to the vendor's SaaS platform and NYU provisioned virtual keys will not work.
:::

With the virtual key and the API key in hand, you should now be able to run the following snippet of code:


```python
from portkey_ai import Portkey

portkey = Portkey(
    base_url="https://ai-gateway.apps.cloud.rt.nyu.edu/v1/",
    api_key="", # Replace with your API key!
)

completion = portkey.chat.completions.create(
    model="@vertexai/gemini-2.5-flash", # Replace with a model available to you!
    messages=[
        {"role": "system", "content": "You are not a helpful assistant"},
        {
            "role": "user",
            "content": "Complete the following sentence:The sun is shining and the sky is",
        },
    ],
)

print(completion)
```

Once the script is executed, you can head back to [`app.portkey.ai`](https://app.portkey.ai/login) to view the logs for the call!
